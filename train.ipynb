{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62274971-51e1-4c0b-a8d5-5bc4ec3059d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# 定义一个自定义的 Dataset\n",
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.data.iloc[idx, 0]\n",
    "        image = self.data.iloc[idx, 1:].values.astype(np.uint8).reshape(28, 28)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# 定义一个 LightningDataModule\n",
    "class MNISTDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir='', batch_size=64, num_workers=4):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ])\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # 数据集的定义\n",
    "        dataset = MNISTDataset(csv_file=self.data_dir + 'train.csv', transform=self.transform)\n",
    "        \n",
    "        # 将数据集划分为训练集和验证集\n",
    "        train_size = int(0.8 * len(dataset))\n",
    "        val_size = len(dataset) - train_size\n",
    "        self.train_dataset, self.val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=True)\n",
    "\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        # 从 test.csv 文件加载测试数据\n",
    "        test_dataset = MNISTDataset(csv_file=self.data_dir + 'test.csv', transform=self.transform)\n",
    "        return DataLoader(test_dataset, batch_size=self.batch_size, num_workers=self.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea31f3f5-5f2b-41e5-b8c4-333c28c7e7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "# 定义模型\n",
    "class MNISTModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(28 * 28, 128)\n",
    "        self.layer_2 = nn.Linear(128, 10)\n",
    "        self.train_accuracy = Accuracy(task='multiclass', num_classes=10)\n",
    "        self.val_accuracy = Accuracy(task='multiclass', num_classes=10)\n",
    "        self.test_accuracy = Accuracy(task='multiclass', num_classes=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # 展开图像为一维向量\n",
    "        x = F.relu(self.layer_1(x))  # 应用 ReLU 激活函数\n",
    "        x = self.layer_2(x)  # 第二个全连接层\n",
    "        return F.log_softmax(x, dim=1)  # 使用 log_softmax 作为输出\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        \n",
    "        # 计算准确率\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.train_accuracy(preds, y)\n",
    "        \n",
    "        # 记录 loss 和 acc 到进度条\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('train_acc', acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        \n",
    "        # 计算准确率\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.val_accuracy(preds, y)\n",
    "        \n",
    "        # 记录 loss 和 acc 到进度条\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('val_acc', acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        \n",
    "        # 计算准确率\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.test_accuracy(preds, y)\n",
    "        \n",
    "        # 记录 loss 和 acc 到进度条\n",
    "        self.log('test_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('test_acc', acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)  # 使用 Adam 优化器\n",
    "\n",
    "# 初始化数据模块\n",
    "mnist_dm = MNISTDataModule(data_dir='', batch_size=64)\n",
    "\n",
    "# 使用 Trainer 进行训练、验证和测试\n",
    "trainer = pl.Trainer(max_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ef9fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 训练模型\n",
    "trainer.fit(MNISTModel(), mnist_dm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a967a4cf-46c5-4ea5-a440-a977e40289fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/mamba/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "Restoring states from the checkpoint path at /lightning_logs/version_11/checkpoints/epoch=9-step=5250.ckpt\n",
      "Loaded model weights from the checkpoint at /lightning_logs/version_11/checkpoints/epoch=9-step=5250.ckpt\n",
      "/opt/mamba/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 132/132 [00:03<00:00, 37.08it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         val_acc            0.9802380800247192\n",
      "        val_loss            0.06603225320577621\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.06603225320577621, 'val_acc': 0.9802380800247192}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(datamodule=mnist_dm)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
